report: "report/workflow.rst"
configfile: "config/config.yaml"

include: "common.smk"

rule all:
    input:
        expand("results/{sample}.bedgraph", sample=config["inputs"].keys()),
        expand("results/readcounts/{sample}.txt", sample=config["inputs"].keys())

if config['trim']:
    rule fastqc_initial:
        input:
            "resources/reads/{sample}.fastq.gz"
        output:
            "results/qc/initial/fastqc_{sample}.html"
            "results/qc/initial/fastqc_{sample}.zip"
        log:
            "logs/fastqc/{sample}.initial"
        container:
            "docker://staphb/fastqc:0.11.9"
        shell:
            "fastqc {input} --noextract --threads 16 --outdir results/qc/initial/"
    rule trimmomatic:
        input:
            "resources/reads/{sample}.fastq.gz"
        output:
            "results/trimmed/{sample}.fastq.gz"
        log:
            "logs/trimmomatic/{sample}.log"
        container:
            "docker://staphb/trimmomatic:0.38"
        shell:
            "java -jar /Trimmomatic-0.38/trimmomatic-0.38.jar SE -threads 16 {input} {output} SLIDINGWINDOW:4:20"
    rule fastqc_trimmed:
        input:
            "results/mapped/{sample}.bam" # this is aligned farther down
        output:
            "results/qc/trimmed/fastqc_{sample}.html"
            "results/qc/trimmed/fastqc_{sample}.zip"
        log:
            "logs/fastqc/{sample}.aftertrim"
        container:
            "docker://staphb/fastqc:0.11.9"
        shell:
            "fastqc {input} --noextract --threads 16 --outdir results/qc/trimmed/"

if config['aligner'] == 'bowtie':
    rule bowtie_align:
        input:
            # There are multiple index files required here, but we
            # list one with the assumption that the rest are always
            # with it
            ref="resources/bowtie_ref/GRCh38_noalt_as.1.bt2",
            fastq=which_fastq
        output:
            temp("results/mapped/{sample}.sam")
        log:
            "logs/bowtie/{sample}"
        container:
            "docker://biocontainers/bowtie2:v2.4.1_cv1"
        shell:
            "bowtie2 -p 16 -q --local "
                "-x resources/bowtie_ref "
                "-U {input.fastq} "
                "-S {output} 2> {log}.err"

elif config['aligner'] == 'bwa':
    rule bwa_aln:
        input:
            "resources/bwa_ref/Homo_sapiens.GRCh38.dna_rm.primary_assembly.fa.gz",
            which_fastq
        output:
            temp("results/mapped/index/{sample}.sai")
        log:
            "logs/bwa/{sample}.aln"
        container:
            "docker://biocontainers/bwa:v0.7.17_cv1"
        shell:
            "bwa aln -t 16 -q 5 -l 25 -k 2 {input} > {output}"

    rule bwa_samse:
        input:
            "resources/bwa_ref/Homo_sapiens.GRCh38.dna_rm.primary_assembly.fa.gz",
            "results/mapped/index/{sample}.sai",
            which_fastq
        output:
            temp("results/mapped/{sample}.sam")
        log:
            "logs/bwa/{sample}.samse"
        container:
            "docker://biocontainers/bwa:v0.7.17_cv1"
        shell:
            "bwa samse {input} > {output}"

rule sam_to_bam:
    input:
        "results/mapped/{sample}.sam"
    output:
        temp("results/mapped/unsorted/{sample}.bam")
    log:
        "logs/samtools/{sample}.view"
    container:
        "docker://kfdrc/samtools:1.9"
    shell:
        "samtools view -S -b {input} > {output}"

rule sort_bam:
    input:
        "results/mapped/unsorted/{sample}.bam"
    output:
        temp("results/mapped/sorted/{sample}.bam")
    log:
        "logs/samtools/{sample}.sort"
    container:
        "docker://kfdrc/samtools:1.9"
    shell:
        "samtools sort -l 9 -O bam -@ 10 -o {output} {input}" # 768MB memory required per thread?

rule remove_duplicate_reads:
    input:
        "results/mapped/sorted/{sample}.bam"
    output:
        temp("results/mapped/nodupes/{sample}.bam")
    log:
        "logs/picard/{sample}"
    container:
        "docker://broadinstitute/picard:2.27.1"
    shell:
        "java -jar picard.jar MarkDuplicates "
            "I={input} "
            "O={output} "
            "M=logs/picard/{wildcards[sample]}.txt "
            "REMOVE_DUPLICATES=true"

rule remove_blacklisted:
    input:
        bam="results/mapped/nodupes/{sample}.bam",
        blacklist="resources/hg38-blacklist.v2.bed"
    output:
        # The regex valication here is NEEDED to prevent
        # a big infinite loop where snakemake is inferring
        # ever-growing values for "sample"
        "results/mapped/{sample,\w\w\w\d+}.bam"
    log:
        "logs/bedtools/{sample}"
    container:
        "docker://staphb/bedtools:2.30.0"
    shell:
        "bedtools subtract -a {input.bam} -b {input.blacklist} "
        "> {output}"

rule count_reads_stages:
    input:
        "results/mapped/unsorted/{sample}.bam",
        "results/mapped/sorted/{sample}.bam",
        "results/mapped/nodupes/{sample}.bam",
        "results/mapped/{sample}.bam"
    output:
        "results/readcounts/{sample}.txt"
    log:
        "logs/samtools/{sample}.counting"
    container:
        "docker://kfdrc/samtools:1.9"
    shell:
        """
        date > {output}

        for var in ({input})
        do
            echo $var >> {output}
            samtools view -c -F 260 $var >> {output}
        done
        """

rule index_bam:
    input:
        "results/mapped/{sample}.bam"
    output:
        "results/mapped/{sample}.bam.bai"
    log:
        "logs/samtools/{sample}.index"
    container:
        "docker://kfdrc/samtools:1.9"
    shell:
        "samtools index -@ 16 {input}"

# convert accessions to the name of the BAM file we expect:
inputfiles = {}
inputindices = {}
for chip, control in config["inputs"].items():
    inputfiles[chip] = f'results/mapped/{control}.bam'
    inputindices[chip] = f'results/mapped/{control}.bam.bai'

rule make_bedgraph:
    input:
        lb1="results/mapped/{sample}.bam",
        control=lambda wcs: inputfiles[wcs.sample],
        lb1_index="results/mapped/{sample}.bam.bai",
        control_index=lambda wcs: inputindices[wcs.sample],
    output:
        "results/{sample}.bedgraph"
    params:
        binsize=config['binsize']
    log:
        "logs/deeptools/{sample}.log"
    container:
        "docker://stjudecloud/deeptools:1.0.1"
    shell:
        "bamCompare -b1 {input.lb1} -b2 {input.control} "
            "--binSize {params.binsize} --numberOfProcessors 16 "
            "--outFileFormat bedgraph --outFileName {output}"
